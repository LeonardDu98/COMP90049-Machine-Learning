{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should open a data file in tsv or csv, and transform it into a usable format\n",
    "\n",
    "# Import necessary library -- pandas to read file\n",
    "import pandas as pd\n",
    "\n",
    "#Read data from tsv file\n",
    "def load_tsvdata(tsvFileName):\n",
    "    \n",
    "    # Read data and return data\n",
    "    data = pd.read_csv(open(tsvFileName), sep = '\\t')\n",
    "    return data\n",
    "\n",
    "#Read data from csv file\n",
    "def load_csvdata(csvFileName):\n",
    "    \n",
    "    # Read data and return data\n",
    "    data = pd.read_csv(open(csvFileName))\n",
    "    return data\n",
    "\n",
    "#Drop useless columns in FEATURES\n",
    "def preprocess_features(featureStream):\n",
    "    \n",
    "    # 3 columns is useless in features: YTId, year, movieId\n",
    "    featureStream.drop('YTId', axis = 1, inplace = True)\n",
    "    featureStream.drop('year', axis = 1, inplace = True)\n",
    "    featureStream.drop('movieId', axis = 1, inplace = True)\n",
    "\n",
    "#Drop useless columns in LABLES  \n",
    "def preprocess_labels(labelStream):\n",
    "    \n",
    "    # 1 columns is useless in labels: movieId\n",
    "    labelStream.drop('movieId', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 5 files and name variables\n",
    "train_F = load_tsvdata(\"train_features.tsv\")\n",
    "train_L = load_tsvdata(\"train_labels.tsv\")\n",
    "valid_F = load_tsvdata(\"valid_features.tsv\")\n",
    "valid_L = load_tsvdata(\"valid_labels.tsv\")\n",
    "test_F = load_csvdata(\"test_features.csv\")\n",
    "\n",
    "#drop useless columns in different variables.\n",
    "preprocess_features(train_F)\n",
    "preprocess_features(valid_F)\n",
    "preprocess_features(test_F)\n",
    "preprocess_labels(train_L)\n",
    "preprocess_labels(valid_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library -- TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\"\"\" \n",
    "funtion: finish TFIDF process\n",
    "input: column: name of column. eg: 'title', 'tag'\n",
    "       dfmin: int or float. Ignore terms that have a document frequency strictly lower than the given threshold\n",
    "                            If float in range of [0.0, 1.0], the parameter represents a proportion of documents. \n",
    "       dfmax: int or float. similar with dfmin.\n",
    "return: TFIDF for train, valid and test. The features must process same opeartion \n",
    "\n",
    "\"\"\"\n",
    "def TFIDF(column, dfmin = 1, dfmax = 0.5):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', min_df = dfmin, max_df = dfmax)\n",
    "    train = vectorizer.fit_transform(train_F[column].values.astype('U'))\n",
    "    train_TFIDF = pd.DataFrame(train.toarray())\n",
    "    words = vectorizer.get_feature_names()\n",
    "    train_TFIDF.columns = words\n",
    "    \n",
    "    valid = vectorizer.transform(valid_F[column].values.astype('U'))\n",
    "    valid_TFIDF = pd.DataFrame(valid.toarray())\n",
    "    valid_TFIDF.columns = words\n",
    "\n",
    "    test = vectorizer.transform(test_F[column].values.astype('U'))\n",
    "    test_TFIDF = pd.DataFrame(test.toarray())\n",
    "    test_TFIDF.columns = words\n",
    "    return train_TFIDF, valid_TFIDF, test_TFIDF\n",
    "\n",
    "#merge the original data, TFIDF for title and TFIDF for tag to train.\n",
    "def final_input(data, title_TFIDF, tag_TFIDF):\n",
    "    inputdata = pd.concat([data, title_TFIDF, tag_TFIDF], axis=1)\n",
    "    #since we take the key words in title and tag, the raw data is useless now.\n",
    "    inputdata.drop('title', axis = 1, inplace = True)\n",
    "    inputdata.drop('tag', axis = 1, inplace = True)\n",
    "    return inputdata\n",
    "\n",
    "#normaliztion each columns.\n",
    "def normalization():\n",
    "    #store the columns should be droped. If the values of one column are same in every instances, this column is useless.\n",
    "    droplist = []\n",
    "    for i in range(len(train_final.columns)): #Min-Max Normalization or Standard score.\n",
    "        max = train_final.iloc[:,i].max()\n",
    "        min = train_final.iloc[:,i].min()\n",
    "        \n",
    "        if max == min:\n",
    "            droplist.append(train_data.iloc[:,i].name)\n",
    "            continue\n",
    "        #The features must process same opeartion \n",
    "        train_final.iloc[:,i] = (train_final.iloc[:,i] - min)/(max - min)\n",
    "        valid_final.iloc[:,i] = (valid_final.iloc[:,i] - min)/(max - min)\n",
    "        test_final.iloc[:,i] = (test_final.iloc[:,i] - min)/(max - min)\n",
    "        \n",
    "    for i in droplist:\n",
    "        #The features must process same opeartion \n",
    "        train_final.drop(i, axis = 1, inplace = True)\n",
    "        valid_final.drop(i, axis = 1, inplace = True)\n",
    "        test_final.drop(i, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adventures</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>angel</th>\n",
       "      <th>baby</th>\n",
       "      <th>bad</th>\n",
       "      <th>batman</th>\n",
       "      <th>battle</th>\n",
       "      <th>beach</th>\n",
       "      <th>beast</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>wind</th>\n",
       "      <th>wolf</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zombies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5240 rows Ã— 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adventures  america  american  angel  baby  bad  batman  battle  beach  \\\n",
       "0            0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "1            0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "2            0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "3            0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "4            0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "...          ...      ...       ...    ...   ...  ...     ...     ...    ...   \n",
       "5235         0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "5236         0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "5237         0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "5238         0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "5239         0.0      0.0       0.0    0.0   0.0  0.0     0.0     0.0    0.0   \n",
       "\n",
       "      beast  ...  wild  wind  wolf  woman  women  world  year  york  young  \\\n",
       "0       0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "1       0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "2       0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "3       0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "4       0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "...     ...  ...   ...   ...   ...    ...    ...    ...   ...   ...    ...   \n",
       "5235    0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "5236    0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "5237    0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "5238    0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "5239    0.0  ...   0.0   0.0   0.0    0.0    0.0    0.0   0.0   0.0    0.0   \n",
       "\n",
       "      zombies  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "...       ...  \n",
       "5235      0.0  \n",
       "5236      0.0  \n",
       "5237      0.0  \n",
       "5238      0.0  \n",
       "5239      0.0  \n",
       "\n",
       "[5240 rows x 149 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the TFIDF results for \"title\" and \"tag\"\n",
    "train_title_TFIDF, valid_title_TFIDF, test_title_TFIDF = TFIDF('title', 9, 0.3) #(3,0.3) (5,0.3) (7,0.3), (20,0.3)\n",
    "train_tag_TFIDF, valid_tag_TFIDF, test_tag_TFIDF = TFIDF('tag')#(10,0.5) (15,0.5) (20,0.5), (25,0.5)\n",
    "train_title_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge and normalization\n",
    "train_final = final_input(train_F, train_title_TFIDF, train_tag_TFIDF)\n",
    "valid_final = final_input(valid_F, valid_title_TFIDF, valid_tag_TFIDF)\n",
    "test_final = final_input(test_F, test_title_TFIDF, test_tag_TFIDF)\n",
    "normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part define 7 models. I tried all of them. But I only detailed writed Naive Bayes and SVM(SVC) in report.\n",
    "\n",
    "\"\"\"\n",
    "def DeTree(train_X, train_Y): \n",
    "    from sklearn import tree\n",
    "    Dtree = tree.DecisionTreeClassifier(criterion='gini') #entropy\n",
    "    Dtree.fit(train_X, train_L.values.ravel())\n",
    "    return Dtree\n",
    "\n",
    "def RandomF(train_X, train_Y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    Rfc = RandomForestClassifier(criterion='entropy')\n",
    "    Rfc.fit(train_X, train_Y.values.ravel())\n",
    "    return Rfc\n",
    "\n",
    "def KNN(train_X, train_Y, num_neighbors):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors = num_neighbors)# 71, 61, 51, 81, 91\n",
    "    knn.fit(train_X, train_Y.values.ravel())\n",
    "    return knn\n",
    "\"\"\"   \n",
    "\n",
    "def MNB(train_X, train_Y):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(train_X, train_Y.values.ravel())\n",
    "    return mnb\n",
    "\n",
    "def BNB(train_X, train_Y):\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(train_X, train_Y.values.ravel())\n",
    "    return bnb\n",
    "\n",
    "def GNB(train_X, train_Y):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_X, train_Y.values.ravel())\n",
    "    return gnb\n",
    "\n",
    "def SVM(train_X, train_Y):\n",
    "    from sklearn import svm\n",
    "    #svc = svm.SVC(kernel='linear')# linear in OK for this problem, but I tried svm.NuSVC(gamma='auto')\n",
    "    svc = svm.SVC(kernel= 'rbf', random_state = 0)\n",
    "    svc.fit(train_X, train_Y.values.ravel())\n",
    "    return svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn = KNN(train_final, train_L, 71)\n",
    "#mnb = MNB(train_final, train_L)\n",
    "#bnb = BNB(train_final, train_L)\n",
    "#gnb = GNB(train_final, train_L)\n",
    "svm = SVM(train_final, train_L)\n",
    "#detree = DeTree(train_final, train_L)\n",
    "#randomf = RandomF(train_final, train_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for an instance or a set of instances, based on a trained model\n",
    "def predict(model, predict_X):\n",
    "    return model.predict(predict_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions in terms of accuracy\n",
    "def evaluate(predict_real, predict_Y):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(predict_real, predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_Y_knn = predict(knn, valid_final)\n",
    "#predict_Y_mnb = predict(mnb, valid_final)\n",
    "#predict_Y_bnb = predict(bnb, valid_final)\n",
    "#predict_Y_gnb = predict(gnb, valid_final)\n",
    "predict_Y_svm = predict(svm, valid_final)\n",
    "#predict_Y_detree = predict(detree, valid_final)\n",
    "#predict_Y_randomf = predict(randomf, valid_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38127090301003347\n"
     ]
    }
   ],
   "source": [
    "#print(evaluate(valid_L ,predict_Y_knn))\n",
    "#print(evaluate(valid_L ,predict_Y_mnb))\n",
    "#print(evaluate(valid_L ,predict_Y_bnb))\n",
    "#print(evaluate(valid_L ,predict_Y_gnb))\n",
    "print(evaluate(valid_L ,predict_Y_svm))\n",
    "#print(evaluate(valid_L ,predict_Y_detree))\n",
    "#print(evaluate(valid_L ,predict_Y_randomf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the prediction of test and output csv file.\n",
    "def test_submit_files(model):\n",
    "    predict_test = predict(model, test_final)\n",
    "    movieID = load_csvdata(\"test_features.csv\")['movieId']\n",
    "    submit = pd.concat([pd.DataFrame(movieID), pd.DataFrame(predict_test)], axis=1)\n",
    "    submit.columns = ['movieId', 'genres']\n",
    "    submit.to_csv(r'submit.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit_files(svm) # download csv file using svm model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
